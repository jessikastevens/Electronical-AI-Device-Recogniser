{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the provided 'edited-model.py' to incorporate suggested improvements\n",
    "\n",
    "# Modified script content with additional tuning, early stopping, and class distribution checks.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('C:/Users/honey/Documents/placment work/Electronical-AI-Device-Recogniser/khanya/data managment/datasets/acs-f2-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "equipment\n",
      "3     9682\n",
      "5     9388\n",
      "7     9378\n",
      "6     9348\n",
      "2     9272\n",
      "14    9155\n",
      "13    9088\n",
      "8     9015\n",
      "11    9004\n",
      "4     8849\n",
      "12    8810\n",
      "9     8784\n",
      "10    8755\n",
      "1     8688\n",
      "0     8661\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "df = df.drop('time', axis=1)\n",
    "\n",
    "# Convert categorical labels to numeric\n",
    "le = LabelEncoder()\n",
    "df['equipment'] = le.fit_transform(df['equipment'])\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop('equipment', axis=1)\n",
    "y = df['equipment']\n",
    "\n",
    "# Analyze class distribution before SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE:\n",
      "equipment\n",
      "0     9682\n",
      "1     9682\n",
      "2     9682\n",
      "3     9682\n",
      "4     9682\n",
      "5     9682\n",
      "6     9682\n",
      "7     9682\n",
      "8     9682\n",
      "9     9682\n",
      "10    9682\n",
      "11    9682\n",
      "12    9682\n",
      "13    9682\n",
      "14    9682\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze class distribution after SMOTE\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# One-hot encode the target labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_resampled_onehot = to_categorical(y_resampled, num_classes=num_classes)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\honey\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.3047 - loss: 2.0447 - val_accuracy: 0.4717 - val_loss: 1.5137\n",
      "Epoch 2/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4433 - loss: 1.5678 - val_accuracy: 0.5260 - val_loss: 1.3281\n",
      "Epoch 3/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4926 - loss: 1.4120 - val_accuracy: 0.5736 - val_loss: 1.2084\n",
      "Epoch 4/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 1.3109 - val_accuracy: 0.5964 - val_loss: 1.1298\n",
      "Epoch 5/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5515 - loss: 1.2376 - val_accuracy: 0.6148 - val_loss: 1.0762\n",
      "Epoch 6/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5711 - loss: 1.1854 - val_accuracy: 0.6379 - val_loss: 1.0253\n",
      "Epoch 7/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5831 - loss: 1.1398 - val_accuracy: 0.6476 - val_loss: 0.9976\n",
      "Epoch 8/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.5955 - loss: 1.1161 - val_accuracy: 0.6499 - val_loss: 0.9684\n",
      "Epoch 9/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.6067 - loss: 1.0820 - val_accuracy: 0.6674 - val_loss: 0.9414\n",
      "Epoch 10/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.6166 - loss: 1.0595 - val_accuracy: 0.6776 - val_loss: 0.9189\n",
      "Epoch 11/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.6231 - loss: 1.0408 - val_accuracy: 0.6773 - val_loss: 0.9002\n",
      "Epoch 12/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.6316 - loss: 1.0220 - val_accuracy: 0.6951 - val_loss: 0.8855\n",
      "Epoch 13/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.6367 - loss: 1.0062 - val_accuracy: 0.6928 - val_loss: 0.8700\n",
      "Epoch 14/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.6438 - loss: 0.9883 - val_accuracy: 0.7016 - val_loss: 0.8553\n",
      "Epoch 15/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.6470 - loss: 0.9776 - val_accuracy: 0.7037 - val_loss: 0.8406\n",
      "Epoch 16/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.6550 - loss: 0.9595 - val_accuracy: 0.7080 - val_loss: 0.8288\n",
      "Epoch 17/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6590 - loss: 0.9489 - val_accuracy: 0.7124 - val_loss: 0.8158\n",
      "Epoch 18/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.6602 - loss: 0.9440 - val_accuracy: 0.7193 - val_loss: 0.8012\n",
      "Epoch 19/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.6637 - loss: 0.9327 - val_accuracy: 0.7146 - val_loss: 0.8020\n",
      "Epoch 20/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.6721 - loss: 0.9179 - val_accuracy: 0.7226 - val_loss: 0.7866\n",
      "Epoch 21/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.6725 - loss: 0.9111 - val_accuracy: 0.7172 - val_loss: 0.7846\n",
      "Epoch 22/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6737 - loss: 0.9065 - val_accuracy: 0.7278 - val_loss: 0.7773\n",
      "Epoch 23/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.6777 - loss: 0.8988 - val_accuracy: 0.7245 - val_loss: 0.7726\n",
      "Epoch 24/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.6826 - loss: 0.8867 - val_accuracy: 0.7283 - val_loss: 0.7624\n",
      "Epoch 25/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.6810 - loss: 0.8875 - val_accuracy: 0.7296 - val_loss: 0.7568\n",
      "Epoch 26/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6820 - loss: 0.8823 - val_accuracy: 0.7330 - val_loss: 0.7489\n",
      "Epoch 27/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.6841 - loss: 0.8763 - val_accuracy: 0.7289 - val_loss: 0.7478\n",
      "Epoch 28/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.8683 - val_accuracy: 0.7299 - val_loss: 0.7513\n",
      "Epoch 29/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6881 - loss: 0.8630 - val_accuracy: 0.7343 - val_loss: 0.7394\n",
      "Epoch 30/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.6890 - loss: 0.8650 - val_accuracy: 0.7347 - val_loss: 0.7338\n",
      "Epoch 31/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.8569 - val_accuracy: 0.7342 - val_loss: 0.7409\n",
      "Epoch 32/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.6904 - loss: 0.8551 - val_accuracy: 0.7361 - val_loss: 0.7303\n",
      "Epoch 33/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - accuracy: 0.6951 - loss: 0.8454 - val_accuracy: 0.7388 - val_loss: 0.7283\n",
      "Epoch 34/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.6952 - loss: 0.8449 - val_accuracy: 0.7389 - val_loss: 0.7247\n",
      "Epoch 35/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.8397 - val_accuracy: 0.7411 - val_loss: 0.7285\n",
      "Epoch 36/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.6969 - loss: 0.8408 - val_accuracy: 0.7427 - val_loss: 0.7169\n",
      "Epoch 37/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.8377 - val_accuracy: 0.7418 - val_loss: 0.7170\n",
      "Epoch 38/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.6998 - loss: 0.8307 - val_accuracy: 0.7458 - val_loss: 0.7125\n",
      "Epoch 39/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.7028 - loss: 0.8248 - val_accuracy: 0.7486 - val_loss: 0.7078\n",
      "Epoch 40/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7006 - loss: 0.8299 - val_accuracy: 0.7490 - val_loss: 0.7055\n",
      "Epoch 41/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.6998 - loss: 0.8274 - val_accuracy: 0.7496 - val_loss: 0.7061\n",
      "Epoch 42/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.8180 - val_accuracy: 0.7464 - val_loss: 0.7055\n",
      "Epoch 43/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7055 - loss: 0.8233 - val_accuracy: 0.7456 - val_loss: 0.7046\n",
      "Epoch 44/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.7068 - loss: 0.8137 - val_accuracy: 0.7478 - val_loss: 0.6968\n",
      "Epoch 45/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7099 - loss: 0.8062 - val_accuracy: 0.7485 - val_loss: 0.6989\n",
      "Epoch 46/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7084 - loss: 0.8089 - val_accuracy: 0.7491 - val_loss: 0.6928\n",
      "Epoch 47/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.8127 - val_accuracy: 0.7493 - val_loss: 0.7065\n",
      "Epoch 48/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7067 - loss: 0.8111 - val_accuracy: 0.7514 - val_loss: 0.6953\n",
      "Epoch 49/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 0.8073 - val_accuracy: 0.7486 - val_loss: 0.6985\n",
      "Epoch 50/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7097 - loss: 0.8037 - val_accuracy: 0.7505 - val_loss: 0.6950\n",
      "Epoch 51/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.7116 - loss: 0.7992 - val_accuracy: 0.7536 - val_loss: 0.6882\n",
      "Epoch 52/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.8089 - val_accuracy: 0.7523 - val_loss: 0.6889\n",
      "Epoch 53/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.7096 - loss: 0.8055 - val_accuracy: 0.7548 - val_loss: 0.6880\n",
      "Epoch 54/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 0.8055 - val_accuracy: 0.7544 - val_loss: 0.6866\n",
      "Epoch 55/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7119 - loss: 0.7970 - val_accuracy: 0.7526 - val_loss: 0.6826\n",
      "Epoch 56/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.7990 - val_accuracy: 0.7515 - val_loss: 0.6845\n",
      "Epoch 57/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.7155 - loss: 0.7903 - val_accuracy: 0.7546 - val_loss: 0.6802\n",
      "Epoch 58/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.7115 - loss: 0.7995 - val_accuracy: 0.7535 - val_loss: 0.6862\n",
      "Epoch 59/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.7930 - val_accuracy: 0.7559 - val_loss: 0.6817\n",
      "Epoch 60/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.7134 - loss: 0.7921 - val_accuracy: 0.7530 - val_loss: 0.6844\n",
      "Epoch 61/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.7117 - loss: 0.7972 - val_accuracy: 0.7533 - val_loss: 0.6820\n",
      "Epoch 62/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.7156 - loss: 0.7852 - val_accuracy: 0.7568 - val_loss: 0.6790\n",
      "Epoch 63/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.7145 - loss: 0.7888 - val_accuracy: 0.7570 - val_loss: 0.6750\n",
      "Epoch 64/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.7158 - loss: 0.7897 - val_accuracy: 0.7543 - val_loss: 0.6829\n",
      "Epoch 65/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.7175 - loss: 0.7846 - val_accuracy: 0.7543 - val_loss: 0.6840\n",
      "Epoch 66/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.7841 - val_accuracy: 0.7572 - val_loss: 0.6748\n",
      "Epoch 67/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.7840 - val_accuracy: 0.7570 - val_loss: 0.6746\n",
      "Epoch 68/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.7185 - loss: 0.7847 - val_accuracy: 0.7549 - val_loss: 0.6794\n",
      "Epoch 69/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.7182 - loss: 0.7812 - val_accuracy: 0.7587 - val_loss: 0.6718\n",
      "Epoch 70/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7202 - loss: 0.7796 - val_accuracy: 0.7575 - val_loss: 0.6773\n",
      "Epoch 71/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.7205 - loss: 0.7780 - val_accuracy: 0.7619 - val_loss: 0.6738\n",
      "Epoch 72/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.7172 - loss: 0.7835 - val_accuracy: 0.7590 - val_loss: 0.6703\n",
      "Epoch 73/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.7187 - loss: 0.7746 - val_accuracy: 0.7565 - val_loss: 0.6703\n",
      "Epoch 74/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.7204 - loss: 0.7776 - val_accuracy: 0.7625 - val_loss: 0.6640\n",
      "Epoch 75/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.7197 - loss: 0.7756 - val_accuracy: 0.7588 - val_loss: 0.6669\n",
      "Epoch 76/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7238 - loss: 0.7634 - val_accuracy: 0.7575 - val_loss: 0.6704\n",
      "Epoch 77/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.7174 - loss: 0.7800 - val_accuracy: 0.7600 - val_loss: 0.6678\n",
      "Epoch 78/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7172 - loss: 0.7758 - val_accuracy: 0.7549 - val_loss: 0.6722\n",
      "Epoch 79/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.7198 - loss: 0.7734 - val_accuracy: 0.7619 - val_loss: 0.6641\n",
      "Epoch 80/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.7679 - val_accuracy: 0.7611 - val_loss: 0.6644\n",
      "Epoch 81/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.7209 - loss: 0.7726 - val_accuracy: 0.7606 - val_loss: 0.6678\n",
      "Epoch 82/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7230 - loss: 0.7681 - val_accuracy: 0.7611 - val_loss: 0.6596\n",
      "Epoch 83/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7230 - loss: 0.7668 - val_accuracy: 0.7638 - val_loss: 0.6636\n",
      "Epoch 84/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.7226 - loss: 0.7660 - val_accuracy: 0.7609 - val_loss: 0.6642\n",
      "Epoch 85/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.7209 - loss: 0.7731 - val_accuracy: 0.7624 - val_loss: 0.6669\n",
      "Epoch 86/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7222 - loss: 0.7676 - val_accuracy: 0.7612 - val_loss: 0.6674\n",
      "Epoch 87/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7251 - loss: 0.7633 - val_accuracy: 0.7602 - val_loss: 0.6645\n",
      "Epoch 88/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.7623 - val_accuracy: 0.7606 - val_loss: 0.6616\n",
      "Epoch 89/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.7673 - val_accuracy: 0.7684 - val_loss: 0.6578\n",
      "Epoch 90/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.7645 - val_accuracy: 0.7609 - val_loss: 0.6634\n",
      "Epoch 91/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.7237 - loss: 0.7620 - val_accuracy: 0.7655 - val_loss: 0.6617\n",
      "Epoch 92/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7245 - loss: 0.7578 - val_accuracy: 0.7607 - val_loss: 0.6638\n",
      "Epoch 93/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.7256 - loss: 0.7572 - val_accuracy: 0.7627 - val_loss: 0.6681\n",
      "Epoch 94/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.7240 - loss: 0.7620 - val_accuracy: 0.7660 - val_loss: 0.6562\n",
      "Epoch 95/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.7248 - loss: 0.7605 - val_accuracy: 0.7633 - val_loss: 0.6592\n",
      "Epoch 96/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.7243 - loss: 0.7611 - val_accuracy: 0.7585 - val_loss: 0.6616\n",
      "Epoch 97/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.7609 - val_accuracy: 0.7644 - val_loss: 0.6626\n",
      "Epoch 98/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.7586 - val_accuracy: 0.7657 - val_loss: 0.6564\n",
      "Epoch 99/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7268 - loss: 0.7574 - val_accuracy: 0.7667 - val_loss: 0.6536\n",
      "Epoch 100/100\n",
      "\u001b[1m3631/3631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7281 - loss: 0.7562 - val_accuracy: 0.7653 - val_loss: 0.6566\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture with dropout\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),  # Increased dropout for stronger regularization\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),  # Added another dense layer with fewer neurons\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with a lower learning rate for better generalization\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=100, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7678 - loss: 0.6541\n",
      "Test Accuracy: 0.7666804194450378\n",
      "\u001b[1m908/908\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
      "Confusion Matrix:\n",
      "[[1387    7   21   17    2  227   51   22    4   31   20   10  112    3\n",
      "    21]\n",
      " [   1 1856    1    2    0    0    0    0   12    0    0    0    0    0\n",
      "     9]\n",
      " [   0    0  945   16    2  386  166  184   18    0    1    8  171    2\n",
      "     0]\n",
      " [  10    0   25  983    0  554   62  239    2   59    2    0  120    2\n",
      "     0]\n",
      " [   0    0    8    0 1876   15   12   16    0    0    0    0   14    5\n",
      "     0]\n",
      " [   2    0   21   12    0 1700   37    7    0    2    0    0  125    0\n",
      "     0]\n",
      " [   0    0   59    6    0  346 1288  114    5    1    0    0  110    3\n",
      "     0]\n",
      " [   0    0   16   36    5  201   51 1618    0    0    0    0    5    1\n",
      "     0]\n",
      " [  10    9   32    6    0    0   33    0 1769   13    0   47   21    0\n",
      "    12]\n",
      " [  11    1   29   13    2  413   24    2    4 1321    0    8   91    0\n",
      "    22]\n",
      " [  10    0    8    0    0  100   51   71    0    1 1538    0   53  107\n",
      "     0]\n",
      " [  26    0    8    0    0    1    1    0    2   33    0 1814   54    0\n",
      "    10]\n",
      " [   7   13   51    1    0   60   20    1   21   20    6   10 1663    5\n",
      "     5]\n",
      " [   0    0   19    5   13  576   71  272    0    1  193    0   45  752\n",
      "     0]\n",
      " [  18   42    4    0    0   51    6    5   33    8    0   18    1    0\n",
      "  1759]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.81      1935\n",
      "           1       0.96      0.99      0.97      1881\n",
      "           2       0.76      0.50      0.60      1899\n",
      "           3       0.90      0.48      0.62      2058\n",
      "           4       0.99      0.96      0.98      1946\n",
      "           5       0.37      0.89      0.52      1906\n",
      "           6       0.69      0.67      0.68      1932\n",
      "           7       0.63      0.84      0.72      1933\n",
      "           8       0.95      0.91      0.93      1952\n",
      "           9       0.89      0.68      0.77      1941\n",
      "          10       0.87      0.79      0.83      1939\n",
      "          11       0.95      0.93      0.94      1949\n",
      "          12       0.64      0.88      0.74      1883\n",
      "          13       0.85      0.39      0.53      1947\n",
      "          14       0.96      0.90      0.93      1945\n",
      "\n",
      "    accuracy                           0.77     29046\n",
      "   macro avg       0.82      0.77      0.77     29046\n",
      "weighted avg       0.82      0.77      0.77     29046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true_classes, y_pred_classes))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new-scaler1.0.0.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model and the scaler for future use\n",
    "model.save('new-model1.0.0.h5')\n",
    "joblib.dump(scaler, 'new-scaler1.0.0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Return the new path so the user can download it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
