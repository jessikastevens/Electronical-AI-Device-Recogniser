{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the provided 'edited-model.py' to incorporate suggested improvements\n",
    "\n",
    "# Modified script content with additional tuning, early stopping, and class distribution checks.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('C:/Users/honey/Documents/placment work/Electronical-AI-Device-Recogniser/khanya/data managment/datasets/acs-f2-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "equipment\n",
      "Fridges_and_freezers                  10776\n",
      "Fans                                  10772\n",
      "Printers                              10763\n",
      "Shavers_(via_chargers)                10762\n",
      "Televisions_(LCD_or_LED)              10751\n",
      "Computers_stations_(with_monitors)    10747\n",
      "Monitors                              10742\n",
      "Coffee_machines                       10737\n",
      "Hi-Fi_systems_(with_CD_players)       10735\n",
      "Lamps_(compact_fluorescent)           10734\n",
      "Kettles                               10733\n",
      "Mobile_phones_(via_chargers)          10727\n",
      "Laptops_(via_chargers)                10716\n",
      "Microwave_ovens                       10711\n",
      "Lamps_(incandescent)                  10702\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "df = df.drop('time', axis=1)\n",
    "\n",
    "# # Convert categorical labels to numeric\n",
    "# le = LabelEncoder()\n",
    "# df['equipment'] = le.fit_transform(df['equipment'])\n",
    "# class_names = le.classes_\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop('equipment', axis=1)\n",
    "y = df['equipment']\n",
    "\n",
    "# Analyze class distribution before SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Handle class imbalance using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Drop the 'time' column as it's not relevant for prediction\n",
    "df = df.drop('time', axis=1)\n",
    "\n",
    "# Convert categorical labels to numeric\n",
    "le = LabelEncoder()\n",
    "df['equipment'] = le.fit_transform(df['equipment'])\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop('equipment', axis=1)\n",
    "y = df['equipment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2269/4041\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.2933 - loss: 2.1038"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Multiply\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the model architecture with weighted input for 'freq' column and dropout\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "freq_weight = K.constant([[2.0]])  # Convert the weight to a tensor with the same shape as freq_input\n",
    "\n",
    "# Split the input into 'freq' and other features\n",
    "freq_input = input_layer[:, 0:1]\n",
    "other_features = input_layer[:, 1:]\n",
    "\n",
    "# Apply the weight to the 'freq' column\n",
    "weighted_freq = Multiply()([freq_input, freq_weight])\n",
    "\n",
    "# Concatenate the weighted 'freq' column back with the other features\n",
    "weighted_input = Concatenate()([weighted_freq, other_features])\n",
    "\n",
    "# Define the rest of the model\n",
    "x = Dense(256, activation='relu')(weighted_input)\n",
    "x = Dropout(0.3)(x)  # Increased dropout for stronger regularization\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model with a lower learning rate for better generalization\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=100, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot confusion matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43my_true_classes\u001b[49m[:\u001b[38;5;28mlen\u001b[39m(y_pred_classes)], y_pred_classes)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Plot the regular confusion matrix\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_true_classes[:len(y_pred_classes)], y_pred_classes)\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Plot the regular confusion matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Plot the normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and the scaler for future use\n",
    "model.save('new-model1.0.3.keras')\n",
    "joblib.dump(scaler, 'new-scaler1.0.3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Return the new path so the user can download it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
