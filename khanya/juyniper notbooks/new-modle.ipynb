{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the provided 'edited-model.py' to incorporate suggested improvements\n",
    "\n",
    "# Modified script content with additional tuning, early stopping, and class distribution checks.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the tensoflow libarys, these handel the the test/train split of the data, the model creation and the model comparison\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('C:/Users/honey/Documents/placment work/Electronical-AI-Device-Recogniser/khanya/data managment/datasets/acs-f2-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop the 'time' column as it's not relevant for prediction\n",
    "df = df.drop('time', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical labels to numeric\n",
    "le = LabelEncoder()\n",
    "df['equipment'] = le.fit_transform(df['equipment'])\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop('equipment', axis=1)\n",
    "y = df['equipment']\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_resampled_onehot = to_categorical(y_resampled)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Multiply\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# Define the model architecture with weighted input for 'freq' column and dropout\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "freq_weight = K.constant([[2.0]])  # Convert the weight to a tensor with the same shape as freq_input\n",
    "\n",
    "# Split the input into 'freq' and other features\n",
    "freq_input = input_layer[:, 0:1]\n",
    "other_features = input_layer[:, 1:]\n",
    "\n",
    "# Apply the weight to the 'freq' column\n",
    "weighted_freq = Multiply()([freq_input, freq_weight])\n",
    "\n",
    "# Concatenate the weighted 'freq' column back with the other features\n",
    "weighted_input = Concatenate()([weighted_freq, other_features])\n",
    "\n",
    "# Define the rest of the model\n",
    "x = Dense(256, activation='relu')(weighted_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "num_classes = y_resampled_onehot.shape[1]\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model with a lower learning rate for better generalization\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=100, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and the scaler for future use\n",
    "model.save('new-model1.0.4.keras')\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "joblib.dump(scaler, 'new-scaler1.0.4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nbformat\n",
    "\n",
    "# TensorBoard setup cell\n",
    "tensorboard_setup_simple = nbformat.v4.new_code_cell(\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Define a function to create TensorBoard callback for different models\n",
    "def get_tensorboard_callback(log_dir_name):\n",
    "  log_dir = f\"logs/{log_dir_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  return TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\"\"\")\n",
    "\n",
    "# TensorBoard example model training cell\n",
    "train_model_with_tensorboard_simple = nbformat.v4.new_code_cell(\"\"\"\n",
    "# Create TensorBoard callback for the model\n",
    "tensorboard_callback = get_tensorboard_callback(\"your_model_name\")\n",
    "\n",
    "# Train your model (Replace 'model' with your actual model variable)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), \n",
    "                    callbacks=[tensorboard_callback])\n",
    "\"\"\")\n",
    "\n",
    "# TensorBoard launch cell\n",
    "launch_tensorboard_simple = nbformat.v4.new_code_cell(\"\"\"\n",
    "# Launch TensorBoard to compare models\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/\n",
    "\"\"\")\n",
    "\n",
    "# Insert the simplified TensorBoard cells into the notebook\n",
    "nb_content['cells'].insert(2, tensorboard_setup_simple)\n",
    "nb_content['cells'].append(train_model_with_tensorboard_simple)\n",
    "nb_content['cells'].append(launch_tensorboard_simple)\n",
    "\n",
    "# Save the simplified notebook\n",
    "simplified_notebook_path = '/mnt/data/simplified_tensorboard_model.ipynb'\n",
    "with open(simplified_notebook_path, 'w') as f:\n",
    "    nbformat.write(nb_content, f)\n",
    "\n",
    "simplified_notebook_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
