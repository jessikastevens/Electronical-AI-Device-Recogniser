{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modified script content with additional tuning, early stopping, and class distribution checks.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the tensoflow libarys, these handel the the test/train split of the data, the model creation and the model comparison\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Concatenate, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorboard import notebook\n",
    "import os\n",
    "import datetime\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Multiply\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('C:/Users/honey/Documents/placment work/Electronical-AI-Device-Recogniser/khanya/data managment/datasets/acs-f2-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop the 'time' column as it's not relevant for prediction\n",
    "df = df.drop('time', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical labels to numeric\n",
    "le = LabelEncoder()\n",
    "df['equipment'] = le.fit_transform(df['equipment'])\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop('equipment', axis=1)\n",
    "y = df['equipment']\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_resampled_onehot = to_categorical(y_resampled)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Multiply\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Filepath for saving the best model\n",
    "checkpoint_filepath = 'best_model.keras'\n",
    "\n",
    "# Check if the best model exists\n",
    "if os.path.exists(checkpoint_filepath):\n",
    "    print(\"Loading the previously saved best model...\")\n",
    "    model = tf.keras.models.load_model(checkpoint_filepath)\n",
    "else:\n",
    "    print(\"No saved model found. Training a new model...\")\n",
    "\n",
    "    # Define the model architecture with weighted inputs and dropout\n",
    "    input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "    # Define weights for each input feature\n",
    "    weights = K.constant([[4.0, 2.0, 1.5, 1.0, 0.5, 0.2]])  # Adjust these weights as needed\n",
    "\n",
    "    # Apply the weights to the input features\n",
    "    weighted_inputs = Multiply()([input_layer, weights])\n",
    "\n",
    "    # Define the rest of the model\n",
    "    x = Dense(128, activation='relu')(weighted_inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    num_classes = y_resampled_onehot.shape[1]\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model with a lower learning rate for better generalization\n",
    "    initial_learning_rate = 0.0005\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# TensorBoard for logging\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Ensure each model logs to its own separate folder\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# FILEPATH: /c:/Users/honey/Documents/placment work/Electronical-AI-Device-Recogniser/khanya/juyniper notbooks/new-modle.ipynb\n",
    "\n",
    "# Save the best model based on validation accuracy\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',   # You can also monitor 'val_accuracy'\n",
    "    save_best_only=True,  # Only save the best model\n",
    "    mode='min',           # 'min' for loss, 'max' for accuracy\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with early stopping, TensorBoard, and model checkpoint callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, tensorboard_callback, model_checkpoint]\n",
    ")\n",
    "\n",
    "# After training, load the best model for future use (optional if not needed immediately)\n",
    "best_model = tf.keras.models.load_model(checkpoint_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs --host localhost --port 6007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained model and the scaler for future use\n",
    "# model.save('new-model1.0.4.keras')\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# joblib.dump(scaler, 'new-scaler1.0.4.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
