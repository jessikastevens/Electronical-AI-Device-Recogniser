{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modified script content with additional tuning, early stopping, and class distribution checks.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the tensoflow libarys, these handel the the test/train split of the data, the model creation and the model comparison\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Concatenate, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorboard import notebook\n",
    "import os\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('C:/Users/honey/Documents/placment work/Electronical-AI-Device-Recogniser/khanya/data managment/datasets/acs-f2-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop the 'time' column as it's not relevant for prediction\n",
    "df = df.drop('time', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical labels to numeric\n",
    "le = LabelEncoder()\n",
    "df['equipment'] = le.fit_transform(df['equipment'])\n",
    "\n",
    "# Split features and labels\n",
    "X = df.drop('equipment', axis=1)\n",
    "y = df['equipment']\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_resampled_onehot = to_categorical(y_resampled)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1085 - loss: 6.1730 - val_accuracy: 0.2446 - val_loss: 2.1709\n",
      "Epoch 2/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.2392 - loss: 2.1730 - val_accuracy: 0.3142 - val_loss: 1.8942\n",
      "Epoch 3/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3113 - loss: 1.9288 - val_accuracy: 0.3729 - val_loss: 1.6994\n",
      "Epoch 4/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3717 - loss: 1.7615 - val_accuracy: 0.4555 - val_loss: 1.5330\n",
      "Epoch 5/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4208 - loss: 1.6139 - val_accuracy: 0.4841 - val_loss: 1.4463\n",
      "Epoch 6/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4573 - loss: 1.5195 - val_accuracy: 0.5158 - val_loss: 1.3700\n",
      "Epoch 7/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4758 - loss: 1.4594 - val_accuracy: 0.5244 - val_loss: 1.3313\n",
      "Epoch 8/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4878 - loss: 1.4199 - val_accuracy: 0.5365 - val_loss: 1.2835\n",
      "Epoch 9/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5023 - loss: 1.3812 - val_accuracy: 0.5336 - val_loss: 1.2756\n",
      "Epoch 10/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: 1.3577 - val_accuracy: 0.5554 - val_loss: 1.2626\n",
      "Epoch 11/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 1.3317 - val_accuracy: 0.5480 - val_loss: 1.2150\n",
      "Epoch 12/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5209 - loss: 1.3173 - val_accuracy: 0.5701 - val_loss: 1.1990\n",
      "Epoch 13/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5309 - loss: 1.2868 - val_accuracy: 0.5801 - val_loss: 1.1709\n",
      "Epoch 14/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5438 - loss: 1.2641 - val_accuracy: 0.6006 - val_loss: 1.1272\n",
      "Epoch 15/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5565 - loss: 1.2335 - val_accuracy: 0.5952 - val_loss: 1.1229\n",
      "Epoch 16/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5608 - loss: 1.2272 - val_accuracy: 0.6038 - val_loss: 1.0978\n",
      "Epoch 17/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5691 - loss: 1.2060 - val_accuracy: 0.6176 - val_loss: 1.0764\n",
      "Epoch 18/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5740 - loss: 1.1900 - val_accuracy: 0.6187 - val_loss: 1.0755\n",
      "Epoch 19/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5744 - loss: 1.1783 - val_accuracy: 0.6204 - val_loss: 1.0566\n",
      "Epoch 20/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 1.1706 - val_accuracy: 0.6240 - val_loss: 1.0553\n",
      "Epoch 21/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5854 - loss: 1.1570 - val_accuracy: 0.6166 - val_loss: 1.0464\n",
      "Epoch 22/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5854 - loss: 1.1556 - val_accuracy: 0.6260 - val_loss: 1.0479\n",
      "Epoch 23/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5923 - loss: 1.1425 - val_accuracy: 0.6237 - val_loss: 1.0348\n",
      "Epoch 24/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5936 - loss: 1.1380 - val_accuracy: 0.6447 - val_loss: 1.0081\n",
      "Epoch 25/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5977 - loss: 1.1278 - val_accuracy: 0.6436 - val_loss: 0.9942\n",
      "Epoch 26/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 1.1214 - val_accuracy: 0.6417 - val_loss: 1.0088\n",
      "Epoch 27/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6008 - loss: 1.1150 - val_accuracy: 0.6554 - val_loss: 0.9820\n",
      "Epoch 28/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 1.1169 - val_accuracy: 0.6480 - val_loss: 0.9975\n",
      "Epoch 29/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 1.1119 - val_accuracy: 0.6512 - val_loss: 0.9692\n",
      "Epoch 30/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6046 - loss: 1.1034 - val_accuracy: 0.6602 - val_loss: 0.9712\n",
      "Epoch 31/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 1.0946 - val_accuracy: 0.6574 - val_loss: 0.9636\n",
      "Epoch 32/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6091 - loss: 1.0948 - val_accuracy: 0.6576 - val_loss: 0.9682\n",
      "Epoch 33/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6098 - loss: 1.0899 - val_accuracy: 0.6504 - val_loss: 0.9686\n",
      "Epoch 34/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 1.0951 - val_accuracy: 0.6549 - val_loss: 0.9545\n",
      "Epoch 35/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6104 - loss: 1.0860 - val_accuracy: 0.6418 - val_loss: 0.9946\n",
      "Epoch 36/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 1.0795 - val_accuracy: 0.6585 - val_loss: 0.9526\n",
      "Epoch 37/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6145 - loss: 1.0748 - val_accuracy: 0.6703 - val_loss: 0.9360\n",
      "Epoch 38/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6183 - loss: 1.0695 - val_accuracy: 0.6655 - val_loss: 0.9312\n",
      "Epoch 39/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6176 - loss: 1.0706 - val_accuracy: 0.6657 - val_loss: 0.9401\n",
      "Epoch 40/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6143 - loss: 1.0710 - val_accuracy: 0.6558 - val_loss: 0.9624\n",
      "Epoch 41/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6170 - loss: 1.0637 - val_accuracy: 0.6712 - val_loss: 0.9433\n",
      "Epoch 42/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6199 - loss: 1.0574 - val_accuracy: 0.6701 - val_loss: 0.9313\n",
      "Epoch 43/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 1.0606 - val_accuracy: 0.6550 - val_loss: 0.9532\n",
      "Epoch 44/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6201 - loss: 1.0620 - val_accuracy: 0.6636 - val_loss: 0.9306\n",
      "Epoch 45/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6233 - loss: 1.0519 - val_accuracy: 0.6763 - val_loss: 0.9257\n",
      "Epoch 46/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6278 - loss: 1.0416 - val_accuracy: 0.6738 - val_loss: 0.9256\n",
      "Epoch 47/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6268 - loss: 1.0451 - val_accuracy: 0.6730 - val_loss: 0.9261\n",
      "Epoch 48/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6283 - loss: 1.0427 - val_accuracy: 0.6740 - val_loss: 0.9131\n",
      "Epoch 49/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6301 - loss: 1.0413 - val_accuracy: 0.6685 - val_loss: 0.9310\n",
      "Epoch 50/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6284 - loss: 1.0393 - val_accuracy: 0.6639 - val_loss: 0.9312\n",
      "Epoch 51/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6275 - loss: 1.0379 - val_accuracy: 0.6703 - val_loss: 0.9146\n",
      "Epoch 52/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 1.0439 - val_accuracy: 0.6734 - val_loss: 0.9243\n",
      "Epoch 53/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6304 - loss: 1.0350 - val_accuracy: 0.6763 - val_loss: 0.9144\n",
      "Epoch 54/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6316 - loss: 1.0326 - val_accuracy: 0.6640 - val_loss: 0.9346\n",
      "Epoch 55/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6296 - loss: 1.0358 - val_accuracy: 0.6706 - val_loss: 0.9129\n",
      "Epoch 56/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6299 - loss: 1.0293 - val_accuracy: 0.6656 - val_loss: 0.9169\n",
      "Epoch 57/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6343 - loss: 1.0232 - val_accuracy: 0.6769 - val_loss: 0.8967\n",
      "Epoch 58/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6327 - loss: 1.0310 - val_accuracy: 0.6797 - val_loss: 0.8977\n",
      "Epoch 59/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6349 - loss: 1.0254 - val_accuracy: 0.6758 - val_loss: 0.9038\n",
      "Epoch 60/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6340 - loss: 1.0236 - val_accuracy: 0.6661 - val_loss: 0.9121\n",
      "Epoch 61/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6334 - loss: 1.0251 - val_accuracy: 0.6836 - val_loss: 0.8922\n",
      "Epoch 62/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6391 - loss: 1.0099 - val_accuracy: 0.6718 - val_loss: 0.9021\n",
      "Epoch 63/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6368 - loss: 1.0195 - val_accuracy: 0.6751 - val_loss: 0.8929\n",
      "Epoch 64/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6410 - loss: 1.0069 - val_accuracy: 0.6914 - val_loss: 0.8694\n",
      "Epoch 65/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6401 - loss: 1.0105 - val_accuracy: 0.6790 - val_loss: 0.8978\n",
      "Epoch 66/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6405 - loss: 1.0050 - val_accuracy: 0.6768 - val_loss: 0.9041\n",
      "Epoch 67/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6397 - loss: 1.0091 - val_accuracy: 0.6773 - val_loss: 0.8914\n",
      "Epoch 68/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6410 - loss: 1.0013 - val_accuracy: 0.6869 - val_loss: 0.8765\n",
      "Epoch 69/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6420 - loss: 1.0039 - val_accuracy: 0.6898 - val_loss: 0.8823\n",
      "Epoch 70/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6433 - loss: 0.9992 - val_accuracy: 0.6723 - val_loss: 0.8942\n",
      "Epoch 71/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6443 - loss: 0.9988 - val_accuracy: 0.6896 - val_loss: 0.8716\n",
      "Epoch 72/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6381 - loss: 1.0120 - val_accuracy: 0.6892 - val_loss: 0.8797\n",
      "Epoch 73/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6454 - loss: 0.9950 - val_accuracy: 0.6822 - val_loss: 0.8776\n",
      "Epoch 74/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6462 - loss: 0.9927 - val_accuracy: 0.6922 - val_loss: 0.8605\n",
      "Epoch 75/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6461 - loss: 0.9929 - val_accuracy: 0.6821 - val_loss: 0.8803\n",
      "Epoch 76/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6453 - loss: 0.9962 - val_accuracy: 0.6849 - val_loss: 0.8695\n",
      "Epoch 77/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6475 - loss: 0.9874 - val_accuracy: 0.6823 - val_loss: 0.8665\n",
      "Epoch 78/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6465 - loss: 0.9872 - val_accuracy: 0.6879 - val_loss: 0.8733\n",
      "Epoch 79/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6464 - loss: 0.9908 - val_accuracy: 0.6794 - val_loss: 0.8916\n",
      "Epoch 80/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6440 - loss: 0.9926 - val_accuracy: 0.6940 - val_loss: 0.8600\n",
      "Epoch 81/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6492 - loss: 0.9786 - val_accuracy: 0.6807 - val_loss: 0.8841\n",
      "Epoch 82/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6477 - loss: 0.9821 - val_accuracy: 0.6892 - val_loss: 0.8618\n",
      "Epoch 83/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6491 - loss: 0.9793 - val_accuracy: 0.6970 - val_loss: 0.8617\n",
      "Epoch 84/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6503 - loss: 0.9775 - val_accuracy: 0.6940 - val_loss: 0.8752\n",
      "Epoch 85/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6517 - loss: 0.9752 - val_accuracy: 0.6959 - val_loss: 0.8651\n",
      "Epoch 86/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6512 - loss: 0.9747 - val_accuracy: 0.6775 - val_loss: 0.8846\n",
      "Epoch 87/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6497 - loss: 0.9818 - val_accuracy: 0.6907 - val_loss: 0.8578\n",
      "Epoch 88/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6529 - loss: 0.9778 - val_accuracy: 0.6939 - val_loss: 0.8520\n",
      "Epoch 89/100\n",
      "\u001b[1m2021/2021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6522 - loss: 0.9755 - val_accuracy: 0.6965 - val_loss: 0.8601\n",
      "Epoch 90/100\n",
      "\u001b[1m 902/2021\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6571 - loss: 0.9671"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the model architecture with weighted inputs and dropout\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Define weights for each input feature\n",
    "weights = K.constant([[4.0, 2.0, 1.5, 1.0, 0.5, 0.2]])  # Adjust these weights as needed\n",
    "\n",
    "# Apply the weights to the input features\n",
    "weighted_inputs = Multiply()([input_layer, weights])\n",
    "\n",
    "# Define the rest of the model\n",
    "x = Dense(128, activation='relu')(weighted_inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "num_classes = y_resampled_onehot.shape[1]\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model with a lower learning rate for better generalization\n",
    "initial_learning_rate = 0.0005\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=lr_schedule), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define a log directory for TensorBoard\n",
    "log_dir = os.path.join(\"logs\", \"fit\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with early stopping and TensorBoard callback\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=100, \n",
    "                    batch_size=64, \n",
    "                    callbacks=[early_stopping, tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Path to the TensorBoard logs directory\n",
    "log_dir = \"logs/fit\"\n",
    "\n",
    "# Remove the directory and its contents\n",
    "shutil.rmtree(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit/train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained model and the scaler for future use\n",
    "# model.save('new-model1.0.4.keras')\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# joblib.dump(scaler, 'new-scaler1.0.4.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
